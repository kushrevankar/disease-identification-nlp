{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ypw2tW0QFU1",
        "outputId": "61980104-d362-4a6d-e4cd-151ad1dedaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "from transformers import AdamW, BertModel, BertTokenizer\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef-Tt3WxSes9",
        "outputId": "b67517bd-5320-4a44-d391-22acbc69e336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: kushrevankar\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/kuc-hackathon-winter-2018\n"
          ]
        }
      ],
      "source": [
        "od.download('https://www.kaggle.com/datasets/jessicali9530/kuc-hackathon-winter-2018')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx4Wikv1Syl4",
        "outputId": "b72ce0ef-1e2b-4d13-937e-d6eea78d315a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-55-ddcfca6bcedf>\", line 30, in <cell line: 0>\n",
            "    x_train = encode_texts(x_train)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-55-ddcfca6bcedf>\", line 27, in encode_texts\n",
            "    return tokenizer(texts, truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2877, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2965, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3167, in batch_encode_plus\n",
            "    return self._batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 888, in _batch_encode_plus\n",
            "    first_ids = get_input_ids(ids)\n",
            "                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 855, in get_input_ids\n",
            "    tokens = self.tokenize(text, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
            "    tokens = self.tokens_trie.split(text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-55-ddcfca6bcedf>\", line 30, in <cell line: 0>\n",
            "    x_train = encode_texts(x_train)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-55-ddcfca6bcedf>\", line 27, in encode_texts\n",
            "    return tokenizer(texts, truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2877, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2965, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3167, in batch_encode_plus\n",
            "    return self._batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 888, in _batch_encode_plus\n",
            "    first_ids = get_input_ids(ids)\n",
            "                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 855, in get_input_ids\n",
            "    tokens = self.tokenize(text, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
            "    tokens = self.tokens_trie.split(text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-55-ddcfca6bcedf>\", line 30, in <cell line: 0>\n",
            "    x_train = encode_texts(x_train)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-55-ddcfca6bcedf>\", line 27, in encode_texts\n",
            "    return tokenizer(texts, truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2877, in __call__\n",
            "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 2965, in _call_one\n",
            "    return self.batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\", line 3167, in batch_encode_plus\n",
            "    return self._batch_encode_plus(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 888, in _batch_encode_plus\n",
            "    first_ids = get_input_ids(ids)\n",
            "                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 855, in get_input_ids\n",
            "    tokens = self.tokenize(text, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line 662, in tokenize\n",
            "    tokens = self.tokens_trie.split(text)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\", line None, in split\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n",
            "    self.showtraceback()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n",
            "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1686, in getframeinfo\n",
            "    start = lineno - 1 - context//2\n",
            "            ~~~~~~~^~~\n",
            "TypeError: unsupported operand type(s) for -: 'NoneType' and 'int'\n"
          ]
        }
      ],
      "source": [
        "EMBED_SIZE = 300\n",
        "BERT_MODEL = 'prajjwal1/bert-mini'\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load dataset\n",
        "kaggle_train = pd.read_csv('/content/kuc-hackathon-winter-2018/drugsComTrain_raw.csv')\n",
        "kaggle_test = pd.read_csv('/content/kuc-hackathon-winter-2018/drugsComTest_raw.csv')\n",
        "\n",
        "# Combine train & test sets\n",
        "main_x = kaggle_train['review'].tolist() + kaggle_test['review'].tolist()\n",
        "main_y = kaggle_train['condition'].tolist() + kaggle_test['condition'].tolist()\n",
        "\n",
        "\n",
        "\n",
        "# Use full dataset (remove slicing)\n",
        "vocab = list(set(main_y))  # Get all unique labels\n",
        "i_to_x = {i: label for i, label in enumerate(vocab)}\n",
        "x_to_i = {label: i for i, label in enumerate(vocab)}\n",
        "\n",
        "# Split dataset without stratification\n",
        "x_train, x_test, y_train, y_test = train_test_split(main_x, main_y, test_size=0.2, random_state=42)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "def encode_texts(texts):\n",
        "    return tokenizer(texts, truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
        "\n",
        "# Encode & move to device\n",
        "x_train = encode_texts(x_train)\n",
        "y_train = torch.tensor([x_to_i[y] for y in y_train], dtype=torch.long).to(device)\n",
        "train_dataset = TensorDataset(x_train['input_ids'], x_train['attention_mask'], x_train['token_type_ids'], y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "x_test = encode_texts(x_test)\n",
        "y_test = torch.tensor([x_to_i[y] for y in y_test], dtype=torch.long).to(device)\n",
        "test_dataset = TensorDataset(x_test['input_ids'], x_test['attention_mask'], x_test['token_type_ids'], y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "x_val = encode_texts(x_val)\n",
        "y_val = torch.tensor([x_to_i[y] for y in y_val], dtype=torch.long).to(device)\n",
        "val_dataset = TensorDataset(x_val['input_ids'], x_val['attention_mask'], x_val['token_type_ids'], y_val)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKMR4pjsnW2C",
        "outputId": "ae1428c8-aa86-48de-e1c5-af913019270f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 3, Test size: 3, Val size: 3\n",
            "Total dataset size: 500\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train size: {len(x_train)}, Test size: {len(x_test)}, Val size: {len(x_val)}\")\n",
        "print(f\"Total dataset size: {len(main_x)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7Aw9FotRZI7",
        "outputId": "b6d0058c-dd0b-4cfb-a09a-6f4590a78be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(4.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.13392857142857142\n",
            "Train F1 score:  0.23028545074606935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.1830, device='cuda:0')\n",
            "Dev Accuracy:  0.06\n",
            "Dev F1 score:  0.11320754716981134\n",
            "Epoch:  2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  8.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(4.0783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.171875\n",
            "Train F1 score:  0.2821382752912228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.3682, device='cuda:0')\n",
            "Dev Accuracy:  0.24\n",
            "Dev F1 score:  0.3870967741935484\n",
            "Epoch:  3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  8.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(4.0368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.18526785714285715\n",
            "Train F1 score:  0.30921034890959703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 13.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.3251, device='cuda:0')\n",
            "Dev Accuracy:  0.24\n",
            "Dev F1 score:  0.3870967741935484\n",
            "Epoch:  4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.9249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.19196428571428573\n",
            "Train F1 score:  0.31398116353705685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.0403, device='cuda:0')\n",
            "Dev Accuracy:  0.24\n",
            "Dev F1 score:  0.36244897959183675\n",
            "Epoch:  5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.7543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.16517857142857142\n",
            "Train F1 score:  0.233674430781898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 13.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.2141, device='cuda:0')\n",
            "Dev Accuracy:  0.18\n",
            "Dev F1 score:  0.1721739130434783\n",
            "Epoch:  6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  8.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.6729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.18973214285714285\n",
            "Train F1 score:  0.2676156401227539\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.4192, device='cuda:0')\n",
            "Dev Accuracy:  0.18\n",
            "Dev F1 score:  0.18514285714285714\n",
            "Epoch:  7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.22991071428571427\n",
            "Train F1 score:  0.29598602547943936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 13.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(4.6388, device='cuda:0')\n",
            "Dev Accuracy:  0.22\n",
            "Dev F1 score:  0.22863636363636364\n",
            "Epoch:  8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.25669642857142855\n",
            "Train F1 score:  0.3203134159378726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 13.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(5.0251, device='cuda:0')\n",
            "Dev Accuracy:  0.18\n",
            "Dev F1 score:  0.16363636363636364\n",
            "Epoch:  9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  7.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.2056, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.25\n",
            "Train F1 score:  0.30926827192041156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(5.0738, device='cuda:0')\n",
            "Dev Accuracy:  0.22\n",
            "Dev F1 score:  0.24389805097451275\n",
            "Epoch:  10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00,  8.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss:  tensor(3.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Train Accuracy:  0.24553571428571427\n",
            "Train F1 score:  0.30340886729326233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev Loss:  tensor(5.4248, device='cuda:0')\n",
            "Dev Accuracy:  0.2\n",
            "Dev F1 score:  0.20767676767676768\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DrugClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DrugClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL)\n",
        "    self.lin1 = nn.Linear(self.bert.config.hidden_size, 512)\n",
        "    self.lin2 = nn.Linear(512, len(vocab))\n",
        "    # self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "    output1 = self.lin1(pooled_output)\n",
        "    output2 = self.lin2(output1)\n",
        "    # return self.softmax(output)\n",
        "    return output2\n",
        "\n",
        "model = DrugClassifier().to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "best_model = {'accuracy':-1, 'epoch':-1, 'model':{}, 'optimizer':{}}\n",
        "for epoch in range(EPOCHS):\n",
        "  print('Epoch: ', epoch+1)\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  f1_scores = []\n",
        "  for input_ids, attention_mask, token_type_ids, labels in tqdm(train_dataloader):\n",
        "    model.train()\n",
        "    out = model(input_ids=input_ids.to(device), attention_mask=attention_mask.to(device))\n",
        "    loss = loss_func(out, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    pred = torch.max(out, dim=1, keepdim=True)[1]\n",
        "    pred = pred.view(pred.shape[0]).to(torch.float32).to(device)\n",
        "    acc = accuracy_score(pred.tolist(), labels.tolist())\n",
        "    accuracies.append(acc)\n",
        "    f1 = f1_score(pred.tolist(), labels.tolist(), average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "    losses.append(loss)\n",
        "\n",
        "  print('Train Loss: ', sum(losses)/len(losses))\n",
        "  print('Train Accuracy: ', sum(accuracies)/len(accuracies))\n",
        "  print('Train F1 score: ', sum(f1_scores)/len(f1_scores))\n",
        "\n",
        "  val_accuracies = []\n",
        "  val_losses = []\n",
        "  val_f1 = []\n",
        "  with torch.no_grad():\n",
        "    for input_ids, attention_mask, token_type_ids, labels in tqdm(val_dataloader):\n",
        "      model.eval()\n",
        "      pred = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      loss = loss_func(pred, labels)\n",
        "      pred = torch.max(pred, dim=1, keepdim=True)[1]\n",
        "      pred = pred.view(pred.shape[0]).to(torch.float32)\n",
        "      acc = accuracy_score(pred.tolist(), labels.tolist())\n",
        "      val_accuracies.append(acc)\n",
        "      f1 = f1_score(pred.tolist(), labels.tolist(), average='weighted')\n",
        "      val_f1.append(f1)\n",
        "      val_losses.append(loss)\n",
        "    print('Dev Loss: ', sum(val_losses)/len(val_losses))\n",
        "    print('Dev Accuracy: ', sum(val_accuracies)/len(val_accuracies))\n",
        "    print('Dev F1 score: ', sum(val_f1)/len(val_f1))\n",
        "\n",
        "  if best_model['accuracy'] < sum(val_accuracies)/len(val_accuracies):\n",
        "    best_model['accuracy'] = sum(val_accuracies)/len(val_accuracies)\n",
        "    best_model['epoch'] = epoch+1\n",
        "    best_model['model'] = model.state_dict()\n",
        "    best_model['optimizer'] = optimizer.state_dict()\n",
        "\n",
        "torch.save({\n",
        "    'accuracy':best_model['accuracy'],\n",
        "    'epoch':best_model['epoch'],\n",
        "    'model':best_model['model'],\n",
        "    'optimizer':best_model['optimizer']\n",
        "}, './best_model61')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxYgB_v4S1J4",
        "outputId": "982a297f-12e1-4098-9d62-ae5381ea869d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss:  tensor(5.4248, device='cuda:0')\n",
            "Test F1 score:  0.20767676767676768\n",
            "Test Accuracy:  0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_path = './best_model61'\n",
        "checkpoint = torch.load(model_path)\n",
        "model.load_state_dict(checkpoint['model'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\n",
        "test_accuracies = []\n",
        "test_f1_scores = []\n",
        "test_losses = []\n",
        "with torch.no_grad():\n",
        "    for input_ids, attention_mask, token_type_ids, labels in tqdm(val_dataloader):\n",
        "      model.eval()\n",
        "      pred = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      loss = loss_func(pred, labels)\n",
        "      pred = torch.max(pred, dim=1, keepdim=True)[1]\n",
        "      pred = pred.view(pred.shape[0]).to(torch.float32)\n",
        "      acc = accuracy_score(pred.tolist(), labels.tolist())\n",
        "      test_accuracies.append(acc)\n",
        "      f1 = f1_score(pred.tolist(), labels.tolist(), average='weighted')\n",
        "      test_f1_scores.append(f1)\n",
        "      test_losses.append(loss)\n",
        "      print('Test Loss: ', sum(test_losses)/len(test_losses))\n",
        "      print('Test F1 score: ', sum(test_f1_scores)/len(test_f1_scores))\n",
        "      print('Test Accuracy: ', sum(test_accuracies)/len(test_accuracies))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
